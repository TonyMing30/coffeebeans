{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tony/Desktop\n",
      "/Users/tony/Desktop/CoffeeBeansT/feature_extractions_data.csv\n",
      "/Users/tony/Desktop\n",
      "/Users/tony/Desktop/CoffeeBeansT\n",
      "File Found\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "file_name = 'feature_extractions_data.csv'\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = '/Users/tony/Desktop'\n",
    "#file_path_feature_data=current_dir+'\\dataset' (这是原代码，下面是更新后的代码：\n",
    "#使用os.path.join来构建file_path_feature_data，这样可以确保路径在不同的操作系统上都能正确工作)\n",
    "file_path_feature_data = os.path.join(current_dir, 'CoffeeBeansT')\n",
    "print(current_dir)\n",
    "# Combine the current working directory and the file name to get the full file path\n",
    "file_path = os.path.join(file_path_feature_data, file_name)\n",
    "print(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = '/Users/tony/Desktop'\n",
    "print(current_dir)\n",
    "print(file_path_feature_data)\n",
    "# List all files in the current directory\n",
    "files_in_current_dir = os.listdir(current_dir)\n",
    "\n",
    "# Check if the file is in the current directory\n",
    "#if file_name in files_in_current_dir:\n",
    "#    print(\"File found.\")\n",
    "#     trad_df = pd.read_csv(file_path, index_col = False)\n",
    "#else:\n",
    "#    print(\"File not found in the current directory.\")\n",
    "    \n",
    "    \n",
    "#z直接使用‘os.path.exists(file_path)'会更加直接和高效\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File Found\")\n",
    "else:\n",
    "    print(\"File not Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用‘panda’的‘read_csv'函数读取'file_path'路径的CSV文件，结果存储在DataFrame 'trad_df'中。参数'index_col = False'表示不将任何列用作行索引\n",
    "try:\n",
    "    trad_df = pd.read_csv(file_path, index_col = False) \n",
    "    # trad_df.drop(\"Unnamed: 0\",axis=1,inplace=True)?\n",
    "    # trad_df.drop(columns=[\"label\", \"filename\"], inplace=False)\n",
    "    # trad_df[\"label\"]\n",
    "except FileNotFoundError:\n",
    "    print(f\"error: file {file_path} not found. 请检查文件路径是否正确\")\n",
    "    #可以选择退出程序或者继续执行其他代码\n",
    "    #exit() 或 return\n",
    "except PermissionError:\n",
    "    print(f\"error: 没有权限读取文件{file_path}. 请检查文件权限\")\n",
    "    # exit() or return\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"error: file {file_path} is empty\")\n",
    "    #exit() or return\n",
    "except Exception as e:\n",
    "    print(f\"读取文件{file_path}时发生未知错误: {e}\")\n",
    "    #exit() or return\n",
    "trad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # drop string table\n",
    "    #这行代码使用'drop'方法从'trad_df' Dataframe中移除'\"path\"'列。参数'axis=1'表示操作的是列而不是行。\n",
    "trad_df = trad_df.drop(\"path\", axis=1)\n",
    "trad_df = trad_df.drop(\"filename\", axis=1)\n",
    "\n",
    "#KNN method \n",
    "from sklearn.impute import KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "trad_df_imputed = knn_imputer.fit_transform(trad_df)\n",
    "trad_df_imputed = pd.DataFrame(trad_df_imputed, columns=trad_df.columns)\n",
    "\n",
    "trad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average padding\n",
    "#Note: This only applies to numeric columns\n",
    "\n",
    "#trad_df.fillna(trad_df.mean(), inplace=True)\n",
    "\n",
    "\n",
    "#Median fill:\n",
    "#trad_df.fillna(trad_df.median(), inplace=True)\n",
    "\n",
    "\n",
    "#Linear interpolation:\n",
    "#这适用于连续数值数据，假设数据是线性分布的\n",
    "#This applies to continuous numerical data, assuming that the data is linearly distributed\n",
    "\n",
    "#trad_df.interpolate(method='linear', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plurality Filling:\n",
    "#这适用于数值和分类数据。 This applies to numerical and categorical data\n",
    "\n",
    "for column in trad_df.columns:\n",
    "    trad_df[column].fillna(trad_df[column].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_label = np.unique(trad_df['label'])\n",
    "#int_label = []\n",
    "#for l in trad_df['label']:\n",
    "#  result = [x == l for x in unique_label]\n",
    "#  i = np.argmax(result)\n",
    "#  int_label.append(i)\n",
    "\n",
    "#trad_df['label'] = int_label\n",
    "\n",
    "\n",
    "trad_df['label'], _ = pd.factorize(trad_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the data type of each column in the 'trad_df' DataFrame.\n",
    "trad_df.dtypes\n",
    "\n",
    "#此属性返回一个Series，显示'trad_df'中每列的数据类型。对于Pandas DataFrame来说，常见的数据类型包括'int64'(整数)、'float64'(浮点数)、'object'(通常是字符串)等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 'reset_index' method is used to reset the index of the 'trad_df' DataFrame, and by setting the 'drop=True' parameter, it does not add the old index as a column of the DataFrame when resetting the index.\n",
    "trad_df = trad_df.reset_index(drop=True)\n",
    "\n",
    "#将'trad_df'的索引重置为默认的整数索引（从0开始），并且通过指定的'drop=True'来丢弃旧的索引。\n",
    "#如果不设置'drop=True'，旧的索引会被保留下来作为一个新的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks the number of missing values per column in the 'trad_df' DataFrame.\n",
    "trad_df.isnull().sum()\n",
    "\n",
    "#'trad_df.isnull()' 这个方法返回一个与'trad_df'形状相同的布尔类型DataFrame，其中的值表示相应位置的数据是否为缺失值（'True'表示缺失值，'False'表示非缺失值）\n",
    "#'.sum()' 当在'isnull()‘方法的结果上调用'sum()'方法时，它会对每列的布尔值('True'计为0)求和，从而给出每列缺失值的总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将无限值替换为NaN，然后删除含有NaN值的行以清洗数据集：\n",
    "trad_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "trad_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for training purpose\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = trad_df.drop(\"label\",axis=1)\n",
    "y = trad_df[\"label\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2)\n",
    "X_test, X_validate, y_test, y_validate = train_test_split(X_val,y_val,test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis, KNeighborsClassifier)\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelling\n",
    "\n",
    "def get_model(index = -1): \n",
    "  models = [\n",
    "  {\n",
    "      \"name\" : \"RandomForestClassifier\",\n",
    "      \"model\" : RandomForestClassifier()\n",
    "  },\n",
    "  {\n",
    "      \"name\" : \" KNeighborsClassifier\",\n",
    "      \"model\" :  KNeighborsClassifier()\n",
    "  },\n",
    "  {\n",
    "      \"name\" : \"DecisionTreeClassifier\",\n",
    "      \"model\" : tree.DecisionTreeClassifier()\n",
    "  },\n",
    "    {\n",
    "      \"name\" : \"GradientBoostingClassifier\",\n",
    "      \"model\" : GradientBoostingClassifier()\n",
    "  }]\n",
    "\n",
    "  if index == -1:\n",
    "    return len(models)\n",
    "\n",
    "  return models[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):                                #定义了一个名为'train_model'的函数，它接收了一个‘model’字典作为参数，这个字典预期包含模型的名称和实例。\n",
    "  print(\"Traning by {} ...\".format(model[\"name\"]))\n",
    "\n",
    "  try:\n",
    "    m = model[\"model\"]\n",
    "  \n",
    "    m.fit(X_train,y_train)                               #使用训练数据对模型进行拟合\n",
    "\n",
    "    \n",
    "  \n",
    "    score = m.score(X_validate,y_validate)               #在验证集上评估模型性能\n",
    "    # Make predictions on the test data\n",
    "    y_pred = m.predict(X_validate)                       #对验证集进行预测\n",
    "\n",
    "  # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_validate, y_pred)\n",
    "    precision = precision_score(y_validate, y_pred, average='weighted')\n",
    "    recall = recall_score(y_validate, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_validate, y_pred, average='weighted')\n",
    "  #   losses = mean_squared_error(y_validate, y_pred,squared=False)\n",
    "    losses = mean_squared_error(y_validate, y_pred)\n",
    "    loss = f\"{losses:.4f}\"\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"Loss (MSE): {losses:.4f}\")\n",
    "\n",
    "    return m,score,precision,recall,f1,loss\n",
    "  \n",
    "\n",
    "\n",
    "  \n",
    "  except ValueError as e:\n",
    "    print(f\"模型训练失败，数据问题: {e}\")\n",
    "  except KeyError as e:\n",
    "    print(f\"模型训练失败，缺少必要的键: {e}\")\n",
    "  except Exception as e:\n",
    "    print(f\"模型训练时发生未知错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main execution\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "loss = []\n",
    "work_model= []\n",
    "\n",
    "for i in range(get_model()):\n",
    "  model_wrapper = get_model(i)\n",
    "  model = model_wrapper[\"model\"]\n",
    "  model_name = model_wrapper[\"name\"]\n",
    "\n",
    "  m,score,precision,recall,f1,losses = train_model(model_wrapper)\n",
    "#   train_model_deep_learning(model_wrapper)\n",
    "  models.append(model_name)\n",
    "  scores.append(score)\n",
    "  precisions.append(precision)\n",
    "  recalls.append(recall)\n",
    "  f1s.append(f1)\n",
    "  loss.append(losses)\n",
    "  work_model.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#def generate_score_df(models = models, scores = scores, precision = precisions, recall = recalls, f1 = f1s,loss = loss ):\n",
    "#  df_scores = pd.DataFrame(np.array([models,scores,precision,recall,f1,loss]).T,columns=[\"model_name\",\"Accuracy\",\"precision\",\"recall\",\"f1\",\"loss\"])\n",
    "\n",
    "\n",
    "#  return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def generate_score_df(models=models, scores=scores, precision=precisions, recall=recalls, f1=f1s, loss=loss):\n",
    "    try:\n",
    "        # 检查所有列表长度是否一致\n",
    "        lengths = [len(models), len(scores), len(precision), len(recall), len(f1), len(loss)]\n",
    "        if len(set(lengths)) > 1:\n",
    "            raise ValueError(\"The length of the input list is not consistent, please check the input data\")\n",
    "        df_scores = pd.DataFrame(np.array([models, scores, precision, recall, f1, loss]).T, columns=[\"model_name\", \"Accuracy\", \"precision\", \"recall\", \"f1\", \"loss\"])\n",
    "    except ValueError as e:\n",
    "        print(f\"Failed to generate scoring DataFrame:{e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unknown error occured while generating the scoring DataFrame: {e}\")\n",
    "        return None\n",
    "    return df_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
